## Knowledge Transfer via Distillation of Activation Boundaries Formed by Hidden Neurons [AAAI 2019]

Official Pytorch implementation of our AAAI paper [arxiv](https://arxiv.org/abs/1811.03233) .


### Requirements 
Pytorch 0.4.1, torchvision


### Knowledge distillation [(CIFAR-10)](https://www.cs.toronto.edu/~kriz/cifar.html) 

Run file : cifar10_AB_distillation.py

Sample teacher network (WRN 22-4 is included)

### Transfer learning [(MIT_scenes)](http://web.mit.edu/torralba/www/indoor.html) 

Run file : MITscenes_AB_distillation.py 

Please download and parse dataset to train and test folder.

### Citation

If code was helpful, please cite our paper.

Byeongho Heo, Minsik Lee, Sangdoo Yun, Jin Young Choi, "
Knowledge Transfer via Distillation of Activation Boundaries Formed by Hidden Neurons", CoRR, 2018. (on AAAI at 2019 Jan.)



